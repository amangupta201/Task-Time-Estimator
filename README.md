# Neural Network Task Time Estimator

**A neural network built from scratch using pure NumPy - No TensorFlow, No PyTorch**

## [ðŸ”´ LIVE DEMO](https://task-time-estimator-7i1m.onrender.com/)

A full-stack web application that predicts task completion times using a neural network implemented entirely from mathematical fundamentals. This project demonstrates deep understanding of neural network internals, backpropagation, and gradient descent without relying on high-level ML libraries.

## Key Technical Achievements

- **Hand-coded backpropagation algorithm** with mathematical derivations
- **Custom gradient descent implementation** with gradient clipping
- **Real-world prediction accuracy** of Â±28 minutes average error
- **Full-stack deployment** with FastAPI backend and responsive frontend
- **Production-ready architecture** with model persistence and error handling

## Architecture Overview

```
Input Layer (5 features) â†’ Hidden Layer (32 neurons) â†’ Hidden Layer (16 neurons) â†’ Output (1 neuron)
```

**Features:**
- Task category (coding, writing, research, meeting, admin, creative, debugging)
- Complexity level (1-10 scale)
- Description length (5-100 words)
- Hour of day (8 AM - 6 PM)
- Energy level (1-10 scale)

**Output:** Predicted completion time in minutes

## Technical Implementation

### Neural Network Components

- **Activation Functions**: ReLU for hidden layers, linear for output
- **Weight Initialization**: Xavier/He initialization for stable training
- **Loss Function**: Mean Squared Error with custom derivative implementation
- **Optimization**: Mini-batch gradient descent with adaptive learning
- **Regularization**: Gradient clipping to prevent exploding gradients

### Mathematical Foundation

The network implements these core mathematical operations:

```python
# Forward propagation
z = WÂ·x + b
a = ReLU(z)  # Hidden layers
y = W_outÂ·a_final + b_out  # Output layer

# Backpropagation
âˆ‚L/âˆ‚W = (1/m) * a_prev^T Â· Î´
âˆ‚L/âˆ‚b = (1/m) * Î£Î´
Î´ = (W_next^T Â· Î´_next) âŠ™ ReLU'(z)
```

### Performance Metrics

- **Training Samples**: 1,000 synthetic tasks
- **Validation MAE**: ~28 minutes average error
- **Validation MAPE**: ~67% mean absolute percentage error
- **Training Time**: 30 seconds for 1,000 epochs
- **Total Parameters**: ~1,700 trainable weights and biases

## Technology Stack

### Backend
- **FastAPI**: RESTful API with automatic documentation
- **NumPy**: All mathematical operations and matrix computations
- **Python**: Core implementation language

### Frontend
- **Vanilla JavaScript**: No frameworks, pure DOM manipulation
- **HTML5/CSS3**: Responsive design with modern UI components
- **Real-time visualization**: Network activation animation

### Deployment
- **Render**: Cloud deployment with automatic HTTPS
- **GitHub**: Version control and continuous deployment

## Project Structure

```
task-time-estimator/
â”œâ”€â”€ main.py              # Neural network implementation
â”œâ”€â”€ backend.py           # FastAPI server and model serving
â”œâ”€â”€ index.html           # Frontend interface
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ trained_model.pkl    # Serialized trained model
â””â”€â”€ model_info.json     # Model metadata and metrics
```

## API Endpoints

### Core Prediction
- `POST /predict` - Single task time prediction
- `POST /predict/batch` - Multiple task predictions
- `GET /model/info` - Model architecture and accuracy metrics

### Utilities
- `GET /health` - API health check and model status
- `GET /model/weights` - Weight analysis for debugging
- `POST /model/retrain` - Retrain model with new parameters

## Installation and Usage

### Local Development

```bash
# Clone repository
git clone https://github.com/yourusername/task-time-estimator.git
cd task-time-estimator

# Install dependencies
pip install -r requirements.txt

# Start server
python backend.py
```

Visit `http://localhost:8000` for the web interface or `http://localhost:8000/docs` for API documentation.

### API Usage Example

```python
import requests

# Predict task completion time
response = requests.post('https://task-time-estimator-7i1m.onrender.com/predict', json={
    "task_category": 0,        # coding task
    "complexity": 7,           # high complexity
    "description_length": 50,  # moderate description
    "hour_of_day": 10,        # 10 AM
    "energy_level": 8         # high energy
})

print(f"Predicted time: {response.json()['predicted_time']:.1f} minutes")
```

## Model Training Process

The neural network learns from synthetic data that models realistic task completion patterns:

1. **Data Generation**: Creates 1,000 synthetic tasks with realistic time relationships
2. **Feature Engineering**: Normalizes inputs to 0-1 range for stable training  
3. **Training Loop**: 1,000 epochs using mini-batch gradient descent
4. **Validation**: Tracks overfitting with separate validation set
5. **Persistence**: Saves trained model for production deployment

## Key Learning Patterns

The model successfully learns these real-world relationships:

- **Task Complexity**: Exponential scaling (complexity 8 takes much longer than complexity 4)
- **Time of Day**: Peak productivity at 10-11 AM and 3-4 PM  
- **Energy Levels**: Higher energy correlates with faster completion
- **Task Categories**: Debugging takes longer than admin tasks
- **Description Length**: More detailed specifications increase work time

## Educational Value

This project demonstrates understanding of:

- **Linear Algebra**: Matrix operations, dot products, vector operations
- **Calculus**: Partial derivatives, chain rule, gradient computation
- **Machine Learning**: Loss functions, optimization, regularization
- **Software Engineering**: API design, deployment, error handling
- **Full-Stack Development**: Frontend, backend, database persistence

## Performance Considerations

- **Training Efficiency**: Vectorized operations using NumPy
- **Memory Usage**: Efficient matrix storage and computation
- **API Response Time**: <100ms average prediction latency
- **Model Size**: <50KB serialized model for fast loading

## Future Enhancements

- **User Learning**: Incorporate feedback to improve personal predictions
- **Advanced Features**: Project type, team size, historical patterns
- **Mobile Application**: React Native app using the same API
- **Analytics Dashboard**: Productivity insights and trend analysis

## Dependencies

```txt
fastapi==0.104.1    # Web framework
uvicorn==0.24.0     # ASGI server
numpy==1.24.3       # Mathematical operations
matplotlib==3.7.1   # Plotting and visualization
python-multipart==0.0.6  # File upload support
```

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature-name`)
3. Implement changes with tests
4. Submit a pull request with detailed description

## License

MIT License - see LICENSE file for details

---

**This project showcases the ability to implement machine learning algorithms from mathematical fundamentals, demonstrating both theoretical understanding and practical engineering skills required for production AI systems.**
